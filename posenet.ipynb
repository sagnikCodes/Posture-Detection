{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom pycocotools.coco import COCO\nimport cv2\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CocoKeypoints(Dataset):\n    def __init__(self, root, annFile, target_size=(256, 192), flip_prob=0.5):\n        self.root = root\n        self.coco = COCO(annFile)\n        self.target_size = target_size\n        self.flip_prob = flip_prob\n        self.image_ids = [img_id for img_id in self.coco.imgs.keys() \n                        if len(self.coco.getAnnIds(imgIds=img_id, catIds=1)) > 0]\n\n    def __len__(self):\n        return len(self.image_ids)\n\n    def __getitem__(self, idx):\n        img_id = self.image_ids[idx]\n        ann_ids = self.coco.getAnnIds(imgIds=img_id, catIds=1)\n        anns = self.coco.loadAnns(ann_ids)\n        ann = max(anns, key=lambda x: x['num_keypoints'])\n\n        img_info = self.coco.loadImgs(img_id)[0]\n        img_path = os.path.join(self.root, img_info['file_name'])\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        orig_h, orig_w = img.shape[:2]\n\n        img = cv2.resize(img, (self.target_size[1], self.target_size[0]))\n\n        keypoints = np.array(ann['keypoints'], dtype=np.float32).reshape(-1, 3)\n        kp = keypoints[:, :2]\n        visibility = keypoints[:, 2]\n\n        kp[:, 0] = kp[:, 0] * (self.target_size[1] / orig_w)\n        kp[:, 1] = kp[:, 1] * (self.target_size[0] / orig_h)\n\n        if np.random.rand() < self.flip_prob:\n            img = img[:, ::-1, :].copy()\n            kp[:, 0] = self.target_size[1] - kp[:, 0]\n            left = [1, 3, 5, 7, 9, 11, 13, 15]\n            right = [2, 4, 6, 8, 10, 12, 14, 16]\n            kp[left + right] = kp[right + left]\n\n        img = np.ascontiguousarray(img)\n        img = transforms.functional.to_tensor(img)\n        img = transforms.functional.normalize(img, \n                                            mean=[0.485, 0.456, 0.406], \n                                            std=[0.229, 0.224, 0.225])\n\n        heatmap_h, heatmap_w = self.target_size[0]//4, self.target_size[1]//4\n        heatmaps = np.zeros((17, heatmap_h, heatmap_w), dtype=np.float32)\n        \n        for i in range(17):\n            if visibility[i] > 0:\n                x = (kp[i, 0] / self.target_size[1]) * heatmap_w\n                y = (kp[i, 1] / self.target_size[0]) * heatmap_h\n                heatmaps[i] = self._gaussian_kernel(heatmap_h, heatmap_w, x, y, 2)\n        \n        return img, torch.tensor(heatmaps, dtype=torch.float32)\n\n    def _gaussian_kernel(self, height, width, x, y, sigma):\n        xv, yv = np.meshgrid(np.arange(width), np.arange(height))\n        d2 = (xv - x)**2 + (yv - y)**2\n        return np.exp(-d2 / (2 * sigma**2))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"coco_root = '/kaggle/input/coco-2017-dataset/coco2017'\ntrain_img_dir = os.path.join(coco_root, 'train2017')\ntrain_ann_file = os.path.join(coco_root, 'annotations/person_keypoints_train2017.json')\n\ndataset = CocoKeypoints(train_img_dir, train_ann_file)\ntrain_loader = DataLoader(dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for image, heatmap in train_loader:\n    print(image.shape)\n    print(heatmap.shape)\n    break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PoseNet(nn.Module):\n    def __init__(self, num_keypoints=17):\n        super(PoseNet, self).__init__()\n        resnet = models.resnet50(pretrained=True)\n        self.backbone = nn.Sequential(*list(resnet.children())[:-2])\n\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(2048, 1024, kernel_size=4, stride=2, padding=1),  # 8x6 -> 16x12\n            nn.BatchNorm2d(1024),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1),   # 16x12 -> 32x24\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),    # 32x24 -> 64x48\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(256, num_keypoints, kernel_size=3, padding=1)             # Final heatmap\n        )\n\n        self._initialize_weights()\n\n    def _initialize_weights(self):\n        for m in self.decoder.modules():\n            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.decoder(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\n\ndef train(model, train_loader, epochs=10, lr=0.001, device='cuda'):\n    model.to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n\n        for i, (images, heatmaps) in enumerate(train_loader):\n            images = images.to(device)\n            heatmaps = heatmaps.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, heatmaps)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            if i % 50 == 49:\n                print(f'Epoch {epoch+1}, Batch {i+1}: Loss {running_loss/50:.4f}')\n                running_loss = 0.0\n\n        # Save the model after each epoch\n        model_path = f'model_epoch_{epoch+1}.pth'\n        torch.save(model.state_dict(), model_path)\n        print(f'Model saved: {model_path}')\n        \n        # Generate a download link\n        display(FileLink(model_path))\n\n        print(f'Epoch {epoch+1} completed')\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def detect_keypoints(model, image_path, device='cuda'):\n    # Load and preprocess image\n    img = cv2.imread(image_path)\n    orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    orig_h, orig_w = orig_img.shape[:2]\n    \n    img = cv2.resize(orig_img, (192, 256))\n    img_tensor = transforms.functional.to_tensor(img)\n    img_tensor = transforms.functional.normalize(img_tensor,\n                                                mean=[0.485, 0.456, 0.406],\n                                                std=[0.229, 0.224, 0.225]).unsqueeze(0)\n \n    model.eval()\n    with torch.no_grad():\n        heatmaps = model(img_tensor.to(device)).cpu().numpy()[0]\n\n    keypoints = []\n    for i in range(17):\n        hm = heatmaps[i]\n        y, x = np.unravel_index(hm.argmax(), hm.shape)\n        x = (x / 48 * 192) * (orig_w / 192)\n        y = (y / 64 * 256) * (orig_h / 256)\n        keypoints.append((int(x), int(y)))\n \n    plt.figure(figsize=(10, 10))\n    plt.imshow(orig_img)\n    for i, (x, y) in enumerate(keypoints):\n        plt.scatter(x, y, s=50, marker='.', c='red')\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = PoseNet()\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = train(model, train_loader, epochs=10, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T09:31:54.109376Z","iopub.execute_input":"2025-04-07T09:31:54.109692Z","iopub.status.idle":"2025-04-07T13:00:53.681852Z","shell.execute_reply.started":"2025-04-07T09:31:54.109667Z","shell.execute_reply":"2025-04-07T13:00:53.681160Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Batch 50: Loss 2.1402\nEpoch 1, Batch 100: Loss 0.0225\nEpoch 1, Batch 150: Loss 0.0114\nEpoch 1, Batch 200: Loss 0.0071\nEpoch 1, Batch 250: Loss 0.0053\nEpoch 1, Batch 300: Loss 0.0047\nEpoch 1, Batch 350: Loss 0.0048\nEpoch 1, Batch 400: Loss 0.0045\nEpoch 1, Batch 450: Loss 0.0038\nEpoch 1, Batch 500: Loss 0.0036\nEpoch 1, Batch 550: Loss 0.0034\nEpoch 1, Batch 600: Loss 0.0032\nEpoch 1, Batch 650: Loss 0.0036\nEpoch 1, Batch 700: Loss 0.0034\nEpoch 1, Batch 750: Loss 0.0032\nEpoch 1, Batch 800: Loss 0.0032\nEpoch 1, Batch 850: Loss 0.0030\nEpoch 1, Batch 900: Loss 0.0031\nEpoch 1, Batch 950: Loss 0.0030\nEpoch 1, Batch 1000: Loss 0.0030\nEpoch 1, Batch 1050: Loss 0.0032\nEpoch 1, Batch 1100: Loss 0.0032\nEpoch 1, Batch 1150: Loss 0.0029\nEpoch 1, Batch 1200: Loss 0.0029\nEpoch 1, Batch 1250: Loss 0.0027\nEpoch 1, Batch 1300: Loss 0.0028\nEpoch 1, Batch 1350: Loss 0.0028\nEpoch 1, Batch 1400: Loss 0.0027\nEpoch 1, Batch 1450: Loss 0.0027\nEpoch 1, Batch 1500: Loss 0.0027\nEpoch 1, Batch 1550: Loss 0.0027\nEpoch 1, Batch 1600: Loss 0.0029\nEpoch 1, Batch 1650: Loss 0.0027\nEpoch 1, Batch 1700: Loss 0.0027\nEpoch 1, Batch 1750: Loss 0.0027\nEpoch 1, Batch 1800: Loss 0.0027\nEpoch 1, Batch 1850: Loss 0.0027\nEpoch 1, Batch 1900: Loss 0.0026\nEpoch 1, Batch 1950: Loss 0.0027\nEpoch 1, Batch 2000: Loss 0.0026\nModel saved: model_epoch_1.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/model_epoch_1.pth","text/html":"<a href='model_epoch_1.pth' target='_blank'>model_epoch_1.pth</a><br>"},"metadata":{}},{"name":"stdout","text":"Epoch 1 completed\nEpoch 2, Batch 50: Loss 0.0026\nEpoch 2, Batch 100: Loss 0.0028\nEpoch 2, Batch 150: Loss 0.0027\nEpoch 2, Batch 200: Loss 0.0026\nEpoch 2, Batch 250: Loss 0.0026\nEpoch 2, Batch 300: Loss 0.0027\nEpoch 2, Batch 350: Loss 0.0026\nEpoch 2, Batch 400: Loss 0.0027\nEpoch 2, Batch 450: Loss 0.0026\nEpoch 2, Batch 500: Loss 0.0027\nEpoch 2, Batch 550: Loss 0.0028\nEpoch 2, Batch 600: Loss 0.0029\nEpoch 2, Batch 650: Loss 0.0027\nEpoch 2, Batch 700: Loss 0.0028\nEpoch 2, Batch 750: Loss 0.0027\nEpoch 2, Batch 800: Loss 0.0027\nEpoch 2, Batch 850: Loss 0.0027\nEpoch 2, Batch 900: Loss 0.0026\nEpoch 2, Batch 950: Loss 0.0027\nEpoch 2, Batch 1000: Loss 0.0026\nEpoch 2, Batch 1050: Loss 0.0026\nEpoch 2, Batch 1100: Loss 0.0026\nEpoch 2, Batch 1150: Loss 0.0026\nEpoch 2, Batch 1200: Loss 0.0027\nEpoch 2, Batch 1250: Loss 0.0026\nEpoch 2, Batch 1300: Loss 0.0026\nEpoch 2, Batch 1350: Loss 0.0026\nEpoch 2, Batch 1400: Loss 0.0031\nEpoch 2, Batch 1450: Loss 0.0028\nEpoch 2, Batch 1500: Loss 0.0028\nEpoch 2, Batch 1550: Loss 0.0028\nEpoch 2, Batch 1600: Loss 0.0028\nEpoch 2, Batch 1650: Loss 0.0027\nEpoch 2, Batch 1700: Loss 0.0028\nEpoch 2, Batch 1750: Loss 0.0030\nEpoch 2, Batch 1800: Loss 0.0029\nEpoch 2, Batch 1850: Loss 0.0028\nEpoch 2, Batch 1900: Loss 0.0029\nEpoch 2, Batch 1950: Loss 0.0030\nEpoch 2, Batch 2000: Loss 0.0029\nModel saved: model_epoch_2.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/model_epoch_2.pth","text/html":"<a href='model_epoch_2.pth' target='_blank'>model_epoch_2.pth</a><br>"},"metadata":{}},{"name":"stdout","text":"Epoch 2 completed\nEpoch 3, Batch 50: Loss 0.0031\nEpoch 3, Batch 100: Loss 0.0031\nEpoch 3, Batch 150: Loss 0.0029\nEpoch 3, Batch 200: Loss 0.0034\nEpoch 3, Batch 250: Loss 0.0030\nEpoch 3, Batch 300: Loss 0.0031\nEpoch 3, Batch 350: Loss 0.0030\nEpoch 3, Batch 400: Loss 0.0031\nEpoch 3, Batch 450: Loss 0.0032\nEpoch 3, Batch 500: Loss 0.0028\nEpoch 3, Batch 550: Loss 0.0032\nEpoch 3, Batch 600: Loss 0.0031\nEpoch 3, Batch 650: Loss 0.0031\nEpoch 3, Batch 700: Loss 0.0029\nEpoch 3, Batch 750: Loss 0.0034\nEpoch 3, Batch 800: Loss 0.0032\nEpoch 3, Batch 850: Loss 0.0031\nEpoch 3, Batch 900: Loss 0.0031\nEpoch 3, Batch 950: Loss 0.0030\nEpoch 3, Batch 1000: Loss 0.0031\nEpoch 3, Batch 1050: Loss 0.0030\nEpoch 3, Batch 1100: Loss 0.0030\nEpoch 3, Batch 1150: Loss 0.0034\nEpoch 3, Batch 1200: Loss 0.0030\nEpoch 3, Batch 1250: Loss 0.0030\nEpoch 3, Batch 1300: Loss 0.0028\nEpoch 3, Batch 1350: Loss 0.0033\nEpoch 3, Batch 1400: Loss 0.0029\nEpoch 3, Batch 1450: Loss 0.0029\nEpoch 3, Batch 1500: Loss 0.0032\nEpoch 3, Batch 1550: Loss 0.0028\nEpoch 3, Batch 1600: Loss 0.0030\nEpoch 3, Batch 1650: Loss 0.0029\nEpoch 3, Batch 1700: Loss 0.0032\nEpoch 3, Batch 1750: Loss 0.0029\nEpoch 3, Batch 1800: Loss 0.0031\nEpoch 3, Batch 1850: Loss 0.0030\nEpoch 3, Batch 1900: Loss 0.0030\nEpoch 3, Batch 1950: Loss 0.0028\nEpoch 3, Batch 2000: Loss 0.0029\nModel saved: model_epoch_3.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/model_epoch_3.pth","text/html":"<a href='model_epoch_3.pth' target='_blank'>model_epoch_3.pth</a><br>"},"metadata":{}},{"name":"stdout","text":"Epoch 3 completed\nEpoch 4, Batch 50: Loss 0.0030\nEpoch 4, Batch 100: Loss 0.0030\nEpoch 4, Batch 150: Loss 0.0029\nEpoch 4, Batch 200: Loss 0.0029\nEpoch 4, Batch 250: Loss 0.0031\nEpoch 4, Batch 300: Loss 0.0033\nEpoch 4, Batch 350: Loss 0.0030\nEpoch 4, Batch 400: Loss 0.0028\nEpoch 4, Batch 450: Loss 0.0027\nEpoch 4, Batch 500: Loss 0.0033\nEpoch 4, Batch 550: Loss 0.0027\nEpoch 4, Batch 600: Loss 0.0029\nEpoch 4, Batch 650: Loss 0.0028\nEpoch 4, Batch 700: Loss 0.0030\nEpoch 4, Batch 750: Loss 0.0029\nEpoch 4, Batch 800: Loss 0.0030\nEpoch 4, Batch 850: Loss 0.0029\nEpoch 4, Batch 900: Loss 0.0027\nEpoch 4, Batch 950: Loss 0.0031\nEpoch 4, Batch 1000: Loss 0.0028\nEpoch 4, Batch 1050: Loss 0.0029\nEpoch 4, Batch 1100: Loss 0.0029\nEpoch 4, Batch 1150: Loss 0.0028\nEpoch 4, Batch 1200: Loss 0.0029\nEpoch 4, Batch 1250: Loss 0.0029\nEpoch 4, Batch 1300: Loss 0.0029\nEpoch 4, Batch 1350: Loss 0.0028\nEpoch 4, Batch 1400: Loss 0.0028\nEpoch 4, Batch 1450: Loss 0.0029\nEpoch 4, Batch 1500: Loss 0.0029\nEpoch 4, Batch 1550: Loss 0.0028\nEpoch 4, Batch 1600: Loss 0.0030\nEpoch 4, Batch 1650: Loss 0.0029\nEpoch 4, Batch 1700: Loss 0.0028\nEpoch 4, Batch 1750: Loss 0.0028\nEpoch 4, Batch 1800: Loss 0.0027\nEpoch 4, Batch 1850: Loss 0.0029\nEpoch 4, Batch 1900: Loss 0.0028\nEpoch 4, Batch 1950: Loss 0.0029\nEpoch 4, Batch 2000: Loss 0.0027\nModel saved: model_epoch_4.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/model_epoch_4.pth","text/html":"<a href='model_epoch_4.pth' target='_blank'>model_epoch_4.pth</a><br>"},"metadata":{}},{"name":"stdout","text":"Epoch 4 completed\nEpoch 5, Batch 50: Loss 0.0028\nEpoch 5, Batch 100: Loss 0.0027\nEpoch 5, Batch 150: Loss 0.0029\nEpoch 5, Batch 200: Loss 0.0029\nEpoch 5, Batch 250: Loss 0.0027\nEpoch 5, Batch 300: Loss 0.0028\nEpoch 5, Batch 350: Loss 0.0027\nEpoch 5, Batch 400: Loss 0.0028\nEpoch 5, Batch 450: Loss 0.0027\nEpoch 5, Batch 500: Loss 0.0026\nEpoch 5, Batch 550: Loss 0.0028\nEpoch 5, Batch 600: Loss 0.0029\nEpoch 5, Batch 650: Loss 0.0028\nEpoch 5, Batch 700: Loss 0.0028\nEpoch 5, Batch 750: Loss 0.0028\nEpoch 5, Batch 800: Loss 0.0027\nEpoch 5, Batch 850: Loss 0.0029\nEpoch 5, Batch 900: Loss 0.0027\nEpoch 5, Batch 950: Loss 0.0028\nEpoch 5, Batch 1000: Loss 0.0026\nEpoch 5, Batch 1050: Loss 0.0026\nEpoch 5, Batch 1100: Loss 0.0026\nEpoch 5, Batch 1150: Loss 0.0028\nEpoch 5, Batch 1200: Loss 0.0027\nEpoch 5, Batch 1250: Loss 0.0026\nEpoch 5, Batch 1300: Loss 0.0027\nEpoch 5, Batch 1350: Loss 0.0026\nEpoch 5, Batch 1400: Loss 0.0027\nEpoch 5, Batch 1450: Loss 0.0027\nEpoch 5, Batch 1500: Loss 0.0027\nEpoch 5, Batch 1550: Loss 0.0039\nEpoch 5, Batch 1600: Loss 0.0037\nEpoch 5, Batch 1650: Loss 0.0027\nEpoch 5, Batch 1700: Loss 0.0026\nEpoch 5, Batch 1750: Loss 0.0026\nEpoch 5, Batch 1800: Loss 0.0026\nEpoch 5, Batch 1850: Loss 0.0026\nEpoch 5, Batch 1900: Loss 0.0026\nEpoch 5, Batch 1950: Loss 0.0026\nEpoch 5, Batch 2000: Loss 0.0026\nModel saved: model_epoch_5.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/model_epoch_5.pth","text/html":"<a href='model_epoch_5.pth' target='_blank'>model_epoch_5.pth</a><br>"},"metadata":{}},{"name":"stdout","text":"Epoch 5 completed\nEpoch 6, Batch 50: Loss 0.0027\nEpoch 6, Batch 100: Loss 0.0026\nEpoch 6, Batch 150: Loss 0.0026\nEpoch 6, Batch 200: Loss 0.0026\nEpoch 6, Batch 250: Loss 0.0027\nEpoch 6, Batch 300: Loss 0.0026\nEpoch 6, Batch 350: Loss 0.0027\nEpoch 6, Batch 400: Loss 0.0027\nEpoch 6, Batch 450: Loss 0.0026\nEpoch 6, Batch 500: Loss 0.0027\nEpoch 6, Batch 550: Loss 0.0027\nEpoch 6, Batch 600: Loss 0.0028\nEpoch 6, Batch 650: Loss 0.0027\nEpoch 6, Batch 700: Loss 0.0027\nEpoch 6, Batch 750: Loss 0.0027\nEpoch 6, Batch 800: Loss 0.0027\nEpoch 6, Batch 850: Loss 0.0027\nEpoch 6, Batch 900: Loss 0.0027\nEpoch 6, Batch 950: Loss 0.0026\nEpoch 6, Batch 1000: Loss 0.0027\nEpoch 6, Batch 1050: Loss 0.0027\nEpoch 6, Batch 1100: Loss 0.0026\nEpoch 6, Batch 1150: Loss 0.0026\nEpoch 6, Batch 1200: Loss 0.0026\nEpoch 6, Batch 1250: Loss 0.0026\nEpoch 6, Batch 1300: Loss 0.0026\nEpoch 6, Batch 1350: Loss 0.0026\nEpoch 6, Batch 1400: Loss 0.0026\nEpoch 6, Batch 1450: Loss 0.0026\nEpoch 6, Batch 1500: Loss 0.0026\nEpoch 6, Batch 1550: Loss 0.0026\nEpoch 6, Batch 1600: Loss 0.0026\nEpoch 6, Batch 1650: Loss 0.0026\nEpoch 6, Batch 1700: Loss 0.0026\nEpoch 6, Batch 1750: Loss 0.0026\nEpoch 6, Batch 1800: Loss 0.0026\nEpoch 6, Batch 1850: Loss 0.0026\nEpoch 6, Batch 1900: Loss 0.0026\nEpoch 6, Batch 1950: Loss 0.0026\nEpoch 6, Batch 2000: Loss 0.0025\nModel saved: model_epoch_6.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/model_epoch_6.pth","text/html":"<a href='model_epoch_6.pth' target='_blank'>model_epoch_6.pth</a><br>"},"metadata":{}},{"name":"stdout","text":"Epoch 6 completed\nEpoch 7, Batch 50: Loss 0.0027\nEpoch 7, Batch 100: Loss 0.0025\nEpoch 7, Batch 150: Loss 0.0026\nEpoch 7, Batch 200: Loss 0.0027\nEpoch 7, Batch 250: Loss 0.0026\nEpoch 7, Batch 300: Loss 0.0026\nEpoch 7, Batch 350: Loss 0.0026\nEpoch 7, Batch 400: Loss 0.0026\nEpoch 7, Batch 450: Loss 0.0026\nEpoch 7, Batch 500: Loss 0.0025\nEpoch 7, Batch 550: Loss 0.0026\nEpoch 7, Batch 600: Loss 0.0026\nEpoch 7, Batch 650: Loss 0.0026\nEpoch 7, Batch 700: Loss 0.0026\nEpoch 7, Batch 750: Loss 0.0026\nEpoch 7, Batch 800: Loss 0.0026\nEpoch 7, Batch 850: Loss 0.0026\nEpoch 7, Batch 900: Loss 0.0026\nEpoch 7, Batch 950: Loss 0.0025\nEpoch 7, Batch 1000: Loss 0.0026\nEpoch 7, Batch 1050: Loss 0.0026\nEpoch 7, Batch 1100: Loss 0.0026\nEpoch 7, Batch 1150: Loss 0.0025\nEpoch 7, Batch 1200: Loss 0.0026\nEpoch 7, Batch 1250: Loss 0.0026\nEpoch 7, Batch 1300: Loss 0.0025\nEpoch 7, Batch 1350: Loss 0.0026\nEpoch 7, Batch 1400: Loss 0.0025\nEpoch 7, Batch 1450: Loss 0.0026\nEpoch 7, Batch 1500: Loss 0.0026\nEpoch 7, Batch 1550: Loss 0.0026\nEpoch 7, Batch 1600: Loss 0.0026\nEpoch 7, Batch 1650: Loss 0.0026\nEpoch 7, Batch 1700: Loss 0.0049\nEpoch 7, Batch 1750: Loss 0.0026\nEpoch 7, Batch 1800: Loss 0.0025\nEpoch 7, Batch 1850: Loss 0.0025\nEpoch 7, Batch 1900: Loss 0.0025\nEpoch 7, Batch 1950: Loss 0.0025\nEpoch 7, Batch 2000: Loss 0.0025\nModel saved: model_epoch_7.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/model_epoch_7.pth","text/html":"<a href='model_epoch_7.pth' target='_blank'>model_epoch_7.pth</a><br>"},"metadata":{}},{"name":"stdout","text":"Epoch 7 completed\nEpoch 8, Batch 50: Loss 0.0025\nEpoch 8, Batch 100: Loss 0.0026\nEpoch 8, Batch 150: Loss 0.0025\nEpoch 8, Batch 200: Loss 0.0025\nEpoch 8, Batch 250: Loss 0.0025\nEpoch 8, Batch 300: Loss 0.0025\nEpoch 8, Batch 350: Loss 0.0025\nEpoch 8, Batch 400: Loss 0.0025\nEpoch 8, Batch 450: Loss 0.0026\nEpoch 8, Batch 500: Loss 0.0026\nEpoch 8, Batch 550: Loss 0.0025\nEpoch 8, Batch 600: Loss 0.0025\nEpoch 8, Batch 650: Loss 0.0025\nEpoch 8, Batch 700: Loss 0.0025\nEpoch 8, Batch 750: Loss 0.0025\nEpoch 8, Batch 800: Loss 0.0026\nEpoch 8, Batch 850: Loss 0.0026\nEpoch 8, Batch 900: Loss 0.0026\nEpoch 8, Batch 950: Loss 0.0025\nEpoch 8, Batch 1000: Loss 0.0026\nEpoch 8, Batch 1050: Loss 0.0025\nEpoch 8, Batch 1100: Loss 0.0025\nEpoch 8, Batch 1150: Loss 0.0025\nEpoch 8, Batch 1200: Loss 0.0026\nEpoch 8, Batch 1250: Loss 0.0025\nEpoch 8, Batch 1300: Loss 0.0025\nEpoch 8, Batch 1350: Loss 0.0025\nEpoch 8, Batch 1400: Loss 0.0025\nEpoch 8, Batch 1450: Loss 0.0026\nEpoch 8, Batch 1500: Loss 0.0025\nEpoch 8, Batch 1550: Loss 0.0025\nEpoch 8, Batch 1600: Loss 0.0025\nEpoch 8, Batch 1650: Loss 0.0025\nEpoch 8, Batch 1700: Loss 0.0025\nEpoch 8, Batch 1750: Loss 0.0025\nEpoch 8, Batch 1800: Loss 0.0026\nEpoch 8, Batch 1850: Loss 0.0026\nEpoch 8, Batch 1900: Loss 0.0025\nEpoch 8, Batch 1950: Loss 0.0025\nEpoch 8, Batch 2000: Loss 0.0025\nModel saved: model_epoch_8.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/model_epoch_8.pth","text/html":"<a href='model_epoch_8.pth' target='_blank'>model_epoch_8.pth</a><br>"},"metadata":{}},{"name":"stdout","text":"Epoch 8 completed\nEpoch 9, Batch 50: Loss 0.0025\nEpoch 9, Batch 100: Loss 0.0026\nEpoch 9, Batch 150: Loss 0.0026\nEpoch 9, Batch 200: Loss 0.0025\nEpoch 9, Batch 250: Loss 0.0025\nEpoch 9, Batch 300: Loss 0.0026\nEpoch 9, Batch 350: Loss 0.0025\nEpoch 9, Batch 400: Loss 0.0025\nEpoch 9, Batch 450: Loss 0.0026\nEpoch 9, Batch 500: Loss 0.0025\nEpoch 9, Batch 550: Loss 0.0025\nEpoch 9, Batch 600: Loss 0.0025\nEpoch 9, Batch 650: Loss 0.0025\nEpoch 9, Batch 700: Loss 0.0025\nEpoch 9, Batch 750: Loss 0.0025\nEpoch 9, Batch 800: Loss 0.0025\nEpoch 9, Batch 850: Loss 0.0026\nEpoch 9, Batch 900: Loss 0.0025\nEpoch 9, Batch 950: Loss 0.0025\nEpoch 9, Batch 1000: Loss 0.0025\nEpoch 9, Batch 1050: Loss 0.0025\nEpoch 9, Batch 1100: Loss 0.0025\nEpoch 9, Batch 1150: Loss 0.0025\nEpoch 9, Batch 1200: Loss 0.0025\nEpoch 9, Batch 1250: Loss 0.0025\nEpoch 9, Batch 1300: Loss 0.0026\nEpoch 9, Batch 1350: Loss 0.0026\nEpoch 9, Batch 1400: Loss 0.0026\nEpoch 9, Batch 1450: Loss 0.0026\nEpoch 9, Batch 1500: Loss 0.0025\nEpoch 9, Batch 1550: Loss 0.0025\nEpoch 9, Batch 1600: Loss 0.0025\nEpoch 9, Batch 1650: Loss 0.0026\nEpoch 9, Batch 1700: Loss 0.0026\nEpoch 9, Batch 1750: Loss 0.0025\nEpoch 9, Batch 1800: Loss 0.0025\nEpoch 9, Batch 1850: Loss 0.0026\nEpoch 9, Batch 1900: Loss 0.0025\nEpoch 9, Batch 1950: Loss 0.0026\nEpoch 9, Batch 2000: Loss 0.0026\nModel saved: model_epoch_9.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/model_epoch_9.pth","text/html":"<a href='model_epoch_9.pth' target='_blank'>model_epoch_9.pth</a><br>"},"metadata":{}},{"name":"stdout","text":"Epoch 9 completed\nEpoch 10, Batch 50: Loss 0.0025\nEpoch 10, Batch 100: Loss 0.0025\nEpoch 10, Batch 150: Loss 0.0025\nEpoch 10, Batch 200: Loss 0.0026\nEpoch 10, Batch 250: Loss 0.0026\nEpoch 10, Batch 300: Loss 0.0025\nEpoch 10, Batch 350: Loss 0.0025\nEpoch 10, Batch 400: Loss 0.0025\nEpoch 10, Batch 450: Loss 0.0026\nEpoch 10, Batch 500: Loss 0.0025\nEpoch 10, Batch 550: Loss 0.0026\nEpoch 10, Batch 600: Loss 0.0025\nEpoch 10, Batch 650: Loss 0.0026\nEpoch 10, Batch 700: Loss 0.0025\nEpoch 10, Batch 900: Loss 0.0026\nEpoch 10, Batch 950: Loss 0.0025\nEpoch 10, Batch 1000: Loss 0.0025\nEpoch 10, Batch 1050: Loss 0.0025\nEpoch 10, Batch 1100: Loss 0.0025\nEpoch 10, Batch 1150: Loss 0.0025\nEpoch 10, Batch 1200: Loss 0.0026\nEpoch 10, Batch 1250: Loss 0.0026\nEpoch 10, Batch 1300: Loss 0.0026\nEpoch 10, Batch 1350: Loss 0.0025\nEpoch 10, Batch 1400: Loss 0.0025\nEpoch 10, Batch 1450: Loss 0.0025\nEpoch 10, Batch 1500: Loss 0.0025\nEpoch 10, Batch 1550: Loss 0.0025\nEpoch 10, Batch 1600: Loss 0.0025\nEpoch 10, Batch 1650: Loss 0.0025\nEpoch 10, Batch 1700: Loss 0.0025\nEpoch 10, Batch 1750: Loss 0.0025\nEpoch 10, Batch 1800: Loss 0.0026\nEpoch 10, Batch 1850: Loss 0.0025\nEpoch 10, Batch 1900: Loss 0.0025\nEpoch 10, Batch 1950: Loss 0.0026\nEpoch 10, Batch 2000: Loss 0.0026\nModel saved: model_epoch_10.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/model_epoch_10.pth","text/html":"<a href='model_epoch_10.pth' target='_blank'>model_epoch_10.pth</a><br>"},"metadata":{}},{"name":"stdout","text":"Epoch 10 completed\n","output_type":"stream"}],"execution_count":16}]}